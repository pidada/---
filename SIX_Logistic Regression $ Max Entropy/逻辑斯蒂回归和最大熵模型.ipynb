{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑斯蒂回归和最大熵模型\n",
    ">两个模型都是处理分类问题；都是对数线性模型$logP(Y|X)=wx$。逻辑斯蒂回归是判别模型，最大熵模型是生成模型。\n",
    "\n",
    "#### 逻辑斯蒂回归\n",
    "首先介绍逻辑斯蒂分布：假设X是随机变量，<span class=\"mark\">X服从逻辑斯蒂分布</span>是指X具有如下分布函数$F(x)$和密度函数$f(x)$：\n",
    "$$F(x)=P(X \\leq x)=\\frac{1}{1+e^{-\\frac {(x-u)}{\\gamma}}}$$\n",
    "$$f(x)=F'(x)=\\frac{e^{- \\frac {x-u}{\\gamma}}}{\\gamma ({1+e^{-\\frac {(x-u)}{\\gamma}}})^2}$$\n",
    "- $f(x)$是$F(x)$的导函数\n",
    "- $\\mu$是位置参数\n",
    "- $\\gamma$是形状参数\n",
    "- $F(x)$的图形是条S形曲线，曲线以$(\\mu , \\frac {1}{2})$为对称中心，即满足$$F(-x+\\mu)-\\frac {1}{2}=-F(x+\\mu)+\\frac{1}{2}$$\n",
    "  -  曲线在中心位置增长速度最快，两端增长速度缓慢\n",
    "  - $\\gamma$的值越小，曲线在中心位置增长的越快\n",
    "  \n",
    "#### 二项逻辑斯蒂回归模型\n",
    "二项逻辑斯蒂回归模型是一种分类模型，由条件概率分布$P(Y|X)$表示，$X$取值为实数,$Y$取值为0或者1，条件概率分布满足：$$P(Y=1|x)=\\frac  {e^{(w \\centerdot x + b)}}{1+e^{(w \\centerdot x + b)}}$$$$P(Y=0|x)=1-P(Y=1|x)=\\frac {1}{1+e^{(w \\centerdot x + b)}}$$\n",
    "\n",
    "- $w$称之为权值向量，$b$称之为偏置，$w \\centerdot x$称之为二者的内积\n",
    "- 给定的实例x，根据上面的两个式子可以求出$P(Y=1|x$和$P(Y=0|x)$，将实例x分类到概率值较大的那类\n",
    "- 将权值向量w和偏置b进行扩充，得到：$$w=(w^{(1)}, w^{(2)},...,w^{(n)},b)$$$$x=(x^{(1)},x^{(2)},...,x^{(n)},1)$$逻辑斯蒂回归模型则记为：$$P(Y=1|x)=\\frac  {e^{(w \\centerdot x)}}{1+e^{(w \\centerdot x)}}$$$$P(Y=0|x)=1-P(Y=1|x)=\\frac {1}{1+e^{(w \\centerdot x)}}$$\n",
    "\n",
    "#### 几率\n",
    "一个事件的几率$odds$是指该时间发生的概率和不发生的概率的比值，对数几率$log odds$或者$logit$函数是：$$logit=log \\frac {p}{1-p}$$,对于逻辑斯蒂回归模型而言，$$log\\frac {P(Y=1|x)}{1-P(Y|=1|x)}=w \\centerdot x$$输出$Y=1$的对数几率是输入x的线性函数\n",
    "\n",
    "#### 模型参数估计\n",
    "对于给定的训练数据集T，可以用极大似然估计法来估计模型的参数，假设$$P(Y=1|x)=\\pi (x)$$$$P(Y=0|x)=1 - \\pi (x)$$同时似然函数为$$\\prod _{i=1}{N}[\\pi(x_i)^{y_i}][1-\\pi(x_i)]^{y_i}$$求出对数似然函数$$L(w)$=\\sum _{i=1}^{N}[y_i(w \\centerdot x_i)-log(1+exp(w \\centerdot x_i)]$$对$L(w)$求极大值，得到w的估计值$ \\hat w$，name问题变成了以对数似然函数为目标函数的最优化问题，通常采用的方法是：梯度下降法和拟牛顿法，此时学习到的逻辑斯蒂回归模型变成了$$P(Y=1|x)=\\frac  {e^{(\\hat w \\centerdot x)}}{1+e^{(w \\centerdot x)}}$$$$P(Y=0|x)=\\frac {1}{1+e^{(\\hat w \\centerdot x)}}$$\n",
    "\n",
    "\n",
    "### 最大熵模型\n",
    "最大熵模型是最大熵原理推导实现的，假设离散随机变量X的概率分布是$P(X)$，则其熵是：$$H(P)=-\\sum _x P(x)log P(x)$$，熵满足不等式$$0 \\leq H(P) \\leq log|X|$$其中|X|表示X的个数，当且仅当X的分布是均匀分布的时候取得等号，也就是说X服从均匀分布的时候，熵最大。\n",
    "\n",
    "#### 最大熵模型定义\n",
    "给定数据集T，联合分布$P(X,Y)$的经验分布和边缘分布$P(X)$的经验分布，分别表示为$\\hat P(X,Y)$和$\\hat P(X)$，在这里：$$\\hat P(X=x,Y=y)=\\frac {v(X=x,Y=y)}{N}$$$$\\hat P(X=x)=\\frac {v(X=x)}{N}$$其中，v表示频数，表示样本容量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
